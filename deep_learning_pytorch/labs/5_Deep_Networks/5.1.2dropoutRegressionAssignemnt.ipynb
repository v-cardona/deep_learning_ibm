{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    " <a href=\"http://cocl.us/pytorch_link_top\"><img src = \"http://cocl.us/Pytorch_top\" width = 950, align = \"center\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://ibm.box.com/shared/static/ugcqz6ohbvff804xp84y4kqnvvk3bq1g.png\"  width = 200, align = \"center\">\n",
    "\n",
    "<h1 align=center><font size = 5>Using Dropout in Regression Assignment   </font></h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "in this lab, you will see how adding dropout to your model will decrease overfitting with <code>nn.Sequential</code>.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "<li><a href=\"#ref0\">Make Some Data </a></li>\n",
    "<li><a href=\"#ref1\">Create the Model and Cost Function the Pytorch way</a></li>\n",
    "<li><a href=\"#ref2\">Batch Gradient Descent</a></li>\n",
    "<br>\n",
    "<p></p>\n",
    "Estimated Time Needed: <strong>20 min</strong>\n",
    "</div>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the libraries you need for this lab:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ref0\"></a>\n",
    "<h2 align=center>Get Some Data </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create polynomial dataset objects: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class Data(Dataset):\n",
    "    def __init__(self,N_SAMPLES = 40,noise_std=1,train=True):\n",
    "      \n",
    "      \n",
    "        self.x = torch.linspace(-1, 1, N_SAMPLES).view(-1,1)\n",
    "        self.f=self.x**2\n",
    "        \n",
    "        if train!=True:\n",
    "            torch.manual_seed(1)\n",
    "         \n",
    "            self.y = self.f+noise_std*torch.randn(self.f.size())\n",
    "            self.y=self.y.view(-1,1)\n",
    "            torch.manual_seed(0)\n",
    "        else:\n",
    "            self.y = self.f+noise_std*torch.randn(self.f.size())\n",
    "            self.y=self.y.view(-1,1)\n",
    "    def __getitem__(self,index):    \n",
    "        return self.x[index],self.y[index]\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    def plot(self):\n",
    "        plt.figure(figsize=(6.1, 10))\n",
    "        plt.scatter(self.x.numpy(), self.y.numpy(), label=\"Samples\")\n",
    "        plt.plot(self.x.numpy(), self.f.numpy()  ,label=\"True function\",color='orange')\n",
    "        plt.xlabel(\"x\")\n",
    "        plt.ylabel(\"y\")\n",
    "        plt.xlim((-1, 1))\n",
    "        plt.ylim((-2, 2.5))\n",
    "        plt.legend(loc=\"best\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataset object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set=Data()\n",
    "data_set.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get some validation data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0) \n",
    "validation_set=Data(train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ref1\"></a>\n",
    "<h2 align=center>Create the Model, Optimizer, and Total Loss Function (cost)</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(4) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a three-layer neural network <code>model</code> with a ReLU() activation function for regression. All the appropriate layers should be 300 units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-click __here__ for the solution.\n",
    "\n",
    "<!-- Your answer is below:\n",
    "\n",
    "n_hidden = 30\n",
    "model= torch.nn.Sequential(\n",
    "    torch.nn.Linear(1, n_hidden), \n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(n_hidden, n_hidden),\n",
    "\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(n_hidden, 1),\n",
    ")\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a three-layer neural network <code>model_drop</code> with a ReLU() activation function for regression. All the appropriate layers should be 300 units. Apply dropout to all but the last layer and make the probability of dropout is 50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-click __here__ for the solution.\n",
    "<!-- Your answer is below:\n",
    "n_hidden = 300\n",
    "model_drop= torch.nn.Sequential(\n",
    "    torch.nn.Linear(1, n_hidden),\n",
    "    torch.nn.Dropout(0.5),  \n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(n_hidden, n_hidden),\n",
    "    torch.nn.Dropout(0.5), \n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(n_hidden, 1),\n",
    ")\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ref2\"></a>\n",
    "<h2 align=center>Train the Model via Mini-Batch Gradient Descent </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the model using dropout to training mode; this is the default mode, but it's a good practice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_drop.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model by using the Adam optimizer. See the unit on other optimizers. Use the mean square loss: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_ofit = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "optimizer_drop = torch.optim.Adam(model_drop.parameters(), lr=0.01)\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize a dictionary that stores the training and validation loss for each model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOSS={}\n",
    "LOSS['training data no dropout']=[]\n",
    "LOSS['validation data no dropout']=[]\n",
    "LOSS['training data dropout']=[]\n",
    "LOSS['validation data dropout']=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run 500 iterations of batch gradient decent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=500\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    #make a prediction for both models \n",
    "    yhat = model(data_set.x)\n",
    "    yhat_drop = model_drop(data_set.x)\n",
    "    #calculate the lossf or both models \n",
    "    loss = criterion(yhat, data_set.y)\n",
    "    loss_drop = criterion(yhat_drop, data_set.y)\n",
    "    \n",
    "    #store the loss for  both the training and validation  data for both models \n",
    "    LOSS['training data no dropout'].append(loss.item())\n",
    "    LOSS['validation data no dropout'].append(criterion(model(validation_set.x), validation_set.y).item())\n",
    "    LOSS['training data dropout'].append(loss_drop.item())\n",
    "    model_drop.eval()\n",
    "    LOSS['validation data dropout'].append(criterion(model_drop(validation_set.x), validation_set.y).item())\n",
    "    model_drop.train()\n",
    "    \n",
    "    #clear gradient \n",
    "    optimizer_ofit.zero_grad()\n",
    "    optimizer_drop.zero_grad()\n",
    "    #Backward pass: compute gradient of the loss with respect to all the learnable parameters\n",
    "    loss.backward()\n",
    "    loss_drop.backward()\n",
    "    #the step function on an Optimizer makes an update to its parameters\n",
    "    optimizer_ofit.step()\n",
    "    optimizer_drop.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a prediction by using the test set assign <code>model</code> to yhat and <code>model_drop</code> to yhat_drop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-click __here__ for the solution.\n",
    "<!-- Your answer is below:\n",
    "yhat=model(data_set.x)\n",
    "model_drop.eval()\n",
    "yhat_drop=model_drop(data_set.x),\n",
    ")\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot predictions of both models. Compare them to the training points and the true function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6.1, 10))\n",
    "\n",
    "plt.scatter(data_set.x.numpy(), data_set.y.numpy(), label=\"Samples\")\n",
    "plt.plot(data_set.x.numpy(), data_set.f.numpy()  ,label=\"True function\",color='orange')\n",
    "plt.plot(data_set.x.numpy(),yhat.detach().numpy(),label='no dropout',c='r')\n",
    "plt.plot(data_set.x.numpy(),yhat_drop.detach().numpy(),label=\"dropout\",c='g')\n",
    "\n",
    "\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.xlim((-1, 1))\n",
    "plt.ylim((-2, 2.5))\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the model using dropout does better at tracking the function that generated the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot out the loss for training and validation data on both models:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6.1, 10))\n",
    "for key, value in LOSS.items():\n",
    "    plt.plot(np.log(np.array(value)),label=key)\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"iterations\")\n",
    "    plt.ylabel(\"Log of cost or total loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    " <a href=\"http://cocl.us/pytorch_link_bottom\"><img src = \"http://cocl.us/pytorch_image_bottom\" width = 950, align = \"center\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the Authors:  \n",
    "\n",
    " [Joseph Santarcangelo]( https://www.linkedin.com/in/joseph-s-50398b136/) has a PhD in Electrical Engineering. His research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. \n",
    "\n",
    "Other contributors: [Michelle Carey](  https://www.linkedin.com/in/michelleccarey/) ,[Morvan Youtube channel]( https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg), [Mavis Zhou](  https://www.linkedin.com/in/jiahui-mavis-zhou-a4537814a/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright &copy; 2018 [cognitiveclass.ai](cognitiveclass.ai?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu). This notebook and its source code are released under the terms of the [MIT License](https://bigdatauniversity.com/mit-license/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
